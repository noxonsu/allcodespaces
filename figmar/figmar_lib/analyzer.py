import os
import json
import requests
from pathlib import Path
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional, Union
import base64
import mimetypes # –î–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ data URI
import asyncio # –î–ª—è asyncio.sleep

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ split_image.py
from .split_image import split_image_intellectually

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É—Ç–∏–ª–∏—Ç—ã –∏–∑ figmar_lib.utils
from .utils import escape_markdown, format_analysis_markdown, send_image_safely, send_formatted_message
from aiogram import types # types –Ω—É–∂–µ–Ω –¥–ª—è —Å–∏–≥–Ω–∞—Ç—É—Ä—ã fetch_all_data_and_analyze_figma


# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
COLUMN_WIDTH_THRESHOLD = 2000  # px, –∫–∞–∫ –≤ JS –≤–µ—Ä—Å–∏–∏

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
load_dotenv(dotenv_path=Path(__file__).parent / '.env')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
FIGMA_API_KEY = os.getenv('FIGMA_API_KEY')
OPENAIMODEL_FIGMA_ANALYSIS = os.getenv('OPENAIMODEL_FIGMA_ANALYSIS', 'gpt-4o')

def load_prompt_from_file(file_name: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞."""
    prompt_path = Path(__file__).parent / file_name
    if not prompt_path.exists():
        print(f"–§–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}")
        return ""
    try:
        with open(prompt_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if content:
                print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞: {file_name} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            else:
                print(f"–§–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞ –ø—É—Å—Ç–æ–π: {file_name}")
            return content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –ø—Ä–æ–º–ø—Ç–∞ {prompt_path}: {e}")
        return ""

IMAGE_ANALYSE_PROMPT_TEMPLATE = load_prompt_from_file('.env.image_analyse_prompt')
FINAL_ANALYSE_PROMPT_TEMPLATE = load_prompt_from_file('.env.final_analyse_prompt')


# --- –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π ---
def ensure_dir_exists(dir_path: Union[str, Path]):
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
    path = Path(dir_path)
    if not path.exists():
        path.mkdir(parents=True, exist_ok=True)
        print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞–Ω–∞: {path}")

def save_data_to_file(file_path: Union[str, Path], data: Any, is_json: bool = True):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª."""
    path = Path(file_path)
    try:
        ensure_dir_exists(path.parent)
        with open(path, 'w', encoding='utf-8') if is_json or isinstance(data, str) else open(path, 'wb') as f:
            if is_json:
                json.dump(data, f, indent=2, ensure_ascii=False)
            else:
                f.write(data)
        print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {path}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª {path}: {e}")


# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Figma API ---
def make_figma_api_request(url: str, file_id: str, endpoint_name: str) -> Optional[Dict[str, Any]]:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Figma API."""
    if not FIGMA_API_KEY:
        error_msg = 'Figma API key –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è FIGMA_API_KEY.'
        print(error_msg)
        raise ValueError(error_msg)

    print(f"–ó–∞–ø—Ä–æ—Å –∫ Figma API: {endpoint_name} –¥–ª—è fileId: {file_id}")
    headers = {'X-Figma-Token': FIGMA_API_KEY}
    try:
        response = requests.get(url, headers=headers, timeout=60)
        response.raise_for_status()  # –í—ã–∑–æ–≤–µ—Ç HTTPError –¥–ª—è –ø–ª–æ—Ö–∏—Ö —Å—Ç–∞—Ç—É—Å–æ–≤ (4xx –∏–ª–∏ 5xx)
        return response.json()
    except requests.exceptions.HTTPError as http_err:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {endpoint_name} –∫ Figma API ({response.status_code} {response.reason}): {response.text}")
        raise ValueError(f"–û—à–∏–±–∫–∞ API {endpoint_name}: {response.status_code} {response.reason}. Details: {response.text}") from http_err
    except requests.exceptions.RequestException as req_err:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {endpoint_name} –¥–ª—è fileId {file_id}: {req_err}")
        raise ValueError(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {endpoint_name}: {req_err}") from req_err

async def get_figma_file(file_id: str, base_dir: Path) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ Figma."""
    url = f"https://api.figma.com/v1/files/{file_id}"
    data = make_figma_api_request(url, file_id, "getFigmaFile")
    if data:
        save_data_to_file(base_dir / 'file_info.json', data)
    return data

async def get_figma_node_images(file_id: str, node_ids: List[str], base_dir: Path) -> Optional[Dict[str, str]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ Figma."""
    if not node_ids:
        print("–ù–µ—Ç nodeIds –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
        return None

    ids_query_param = ','.join(node_ids)
    url = f"https://api.figma.com/v1/images/{file_id}?ids={ids_query_param}&format=png"
    
    data = make_figma_api_request(url, file_id, "getFigmaNodeImages")

    if data and data.get('images'):
        images_dir = base_dir / 'images'
        ensure_dir_exists(images_dir)
        downloaded_count = 0
        image_urls_map = {} # –°–æ—Ö—Ä–∞–Ω—è–µ–º URL-—ã –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞

        for node_id, image_url in data['images'].items():
            if image_url:
                image_path = images_dir / f"node_{node_id.replace(':', '_')}.png"
                try:
                    image_response = requests.get(image_url, timeout=60)
                    image_response.raise_for_status()
                    
                    save_data_to_file(image_path, image_response.content, is_json=False)
                    image_urls_map[node_id] = str(image_path.resolve()) # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
                    downloaded_count += 1
                except requests.exceptions.RequestException as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–∑–ª–∞ {node_id}: {e}")
                except Exception as e:
                    print(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–∑–ª–∞ {node_id}: {e}")
            else:
                image_urls_map[node_id] = None # –ï—Å–ª–∏ URL –ø—É—Å—Ç–æ–π

        print(f"–°–∫–∞—á–∞–Ω–æ –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {downloaded_count}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞—Ä—Ç—É node_id –∫ –õ–û–ö–ê–õ–¨–ù–û–ú–£ –ü–£–¢–ò –∫ —Ñ–∞–π–ª—É –∏–ª–∏ None
        return {node_id: str(images_dir / f"node_{node_id.replace(':', '_')}.png") if data['images'].get(node_id) else None 
                for node_id in data['images']}
    else:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–∑–ª–æ–≤ –∏–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç data.images.")
    return None

async def get_figma_comments(file_id: str, base_dir: Path) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ —Ñ–∞–π–ª—É Figma."""
    url = f"https://api.figma.com/v1/files/{file_id}/comments"
    data = make_figma_api_request(url, file_id, "getFigmaComments")
    if data and data.get('comments'):
        save_data_to_file(base_dir / 'comments.json', data)
    else:
        print("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Ö –ø–æ–ª—É—á–µ–Ω–∏–∏.")
        save_data_to_file(base_dir / 'comments.json', {"comments": []})
    return data


# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–∑–æ–≤–∞ OpenAI API ---
def _call_openai_for_figma_analysis(prompt_text: str, image_path: Optional[str] = None, max_tokens: int = 4000) -> str:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—ã–∑–æ–≤ OpenAI API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Figma."""
    if not OPENAI_API_KEY:
        print("–ö–ª—é—á OpenAI API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
        raise ValueError("–ö–ª—é—á OpenAI API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")

    model_name = OPENAIMODEL_FIGMA_ANALYSIS
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENAI_API_KEY}"
    }
    
    messages = [
        {"role": "system", "content": "You are an expert Figma analyzer. Your task is to analyze Figma designs based on provided information and images. Provide detailed and structured responses in Russian."},
    ]
    
    user_message_content = [{"type": "text", "text": prompt_text}]

    if image_path:
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ image_path URL-–æ–º –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–º –ø—É—Ç–µ–º
            if image_path.startswith('http://') or image_path.startswith('https://'):
                user_message_content.append({
                    "type": "image_url",
                    "image_url": {"url": image_path, "detail": "high"}
                })
            elif Path(image_path).exists(): # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
                with open(image_path, "rb") as image_file:
                    base64_image = base64.b64encode(image_file.read()).decode('utf-8')
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º mime type
                mime_type, _ = mimetypes.guess_type(image_path)
                if not mime_type: # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
                    mime_type = "image/png" if image_path.lower().endswith(".png") else "image/jpeg"
                
                user_message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{base64_image}", "detail": "high"}
                })
            else: # –ï—Å–ª–∏ —ç—Ç–æ data URI
                 user_message_content.append({
                    "type": "image_url",
                    "image_url": {"url": image_path, "detail": "high"}
                })
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∞

    messages.append({"role": "user", "content": user_message_content})

    payload = {
        "model": model_name,
        "messages": messages,
        "max_tokens": max_tokens,
    }

    print(f"[FigmaLLM] –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ OpenAI. –ú–æ–¥–µ–ª—å: {model_name}. Max Tokens: {max_tokens}. Image: {'Provided' if image_path else 'Not provided'}")
    
    try:
        response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=payload, timeout=180)
        response.raise_for_status()
        response_data = response.json()
        
        assistant_text = response_data.get('choices', [{}])[0].get('message', {}).get('content')

        if assistant_text is None:
            print(f"[FigmaLLM] –û—Ç–≤–µ—Ç –æ—Ç OpenAI –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. Full response: {response_data}")
            raise ValueError('–û—Ç–≤–µ—Ç –æ—Ç OpenAI –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.')
        
        usage = response_data.get('usage', {})
        input_tokens = usage.get('prompt_tokens', 0)
        output_tokens = usage.get('completion_tokens', 0)
        print(f"[FigmaLLM] Tokens used: Input: {input_tokens}, Output: {output_tokens}")

        return assistant_text.strip()
    except requests.exceptions.HTTPError as e:
        error_body = e.response.text
        print(f"[FigmaLLM] –û—à–∏–±–∫–∞ API OpenAI ({e.response.status_code}): {error_body}")
        raise ValueError(f"–û—à–∏–±–∫–∞ API OpenAI: {e.response.status_code}. Body: {error_body}") from e
    except requests.exceptions.RequestException as e:
        print(f"[FigmaLLM] –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ OpenAI API: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ LLM: {e}") from e
    except (IndexError, KeyError) as e:
        print(f"[FigmaLLM] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ OpenAI: {e}. Response data: {response_data if 'response_data' in locals() else 'N/A'}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ OpenAI: {e}") from e


# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é LLM ---
async def analyze_figma_data_with_llm(text_content: str, image_path: Optional[str] = None, max_tokens: int = 1500) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ Figma —Å –ø–æ–º–æ—â—å—é LLM."""
    if not OPENAI_API_KEY:
        print('OPENAI_API_KEY –¥–ª—è LLM –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ Figma —á–µ—Ä–µ–∑ AI')
        return "OpenAI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –Ω–µ—Ç API –∫–ª—é—á–∞."
    
    print(f"\n–ó–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è Figma –∞–Ω–∞–ª–∏–∑–∞ (max_tokens: {max_tokens}). Image Path: {image_path if image_path else 'Not provided'}")
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –≤–Ω—É—Ç—Ä–∏ async —Ñ—É–Ω–∫—Ü–∏–∏, —Ç.–∫. requests —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å aiohttp –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö HTTP –∑–∞–ø—Ä–æ—Å–æ–≤
        llm_response = _call_openai_for_figma_analysis(text_content, image_path, max_tokens)
        print("–û—Ç–≤–µ—Ç –æ—Ç LLM –¥–ª—è Figma –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª—É—á–µ–Ω.")
        return llm_response
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ Figma —á–µ—Ä–µ–∑ LLM: {e}")
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Figma —á–µ—Ä–µ–∑ LLM: {e}"

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ Figma ---
async def fetch_all_data_and_analyze_figma(figma_url: str, message: types.Message) -> Dict[str, Any]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Figma –∏ –∏—Ö –∞–Ω–∞–ª–∏–∑–∞ —Å –ø–æ–º–æ—â—å—é LLM.
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –æ–±—ä–µ–∫—Ç message –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤.
    """
    print(f"–ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ Figma URL: {figma_url}")
    await message.answer(f"–ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ Figma URL: `{escape_markdown(figma_url)}`", parse_mode='MarkdownV2')
    
    try:
        url_parts = figma_url.split('/')
        file_id_index = url_parts.index('file') + 1 if 'file' in url_parts else url_parts.index('design') + 1
        file_id = url_parts[file_id_index]
    except (ValueError, IndexError):
        error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å fileId –∏–∑ URL: {figma_url}"
        print(error_msg)
        await message.answer(f"‚ùå *–û—à–∏–±–∫–∞*: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å `fileId` –∏–∑ URL: `{escape_markdown(figma_url)}`", parse_mode='MarkdownV2')
        raise ValueError(error_msg)

    print(f"–†–∞–±–æ—Ç–∞–µ–º —Å fileId: {file_id}")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Path.cwd() –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
    # –∏–ª–∏ Path(__file__).parent –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç –∑–∞–ø—É—Å–∫ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ figmar/
    base_project_dir = Path(__file__).parent # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Å–∫—Ä–∏–ø—Ç –≤ figmar/
    base_dir = base_project_dir / 'figma_data' / file_id.replace(r'[^a-zA-Z0-9-_]', '_')
    ensure_dir_exists(base_dir)
    print(f"–î–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {base_dir}")

    analysis_prompt_parts = [f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ (ID: {file_id}) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –µ–≥–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏. –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü, —É–∑–ª–æ–≤, –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, —Å—Ç–∏–ª–µ–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –æ–±—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É.\n\n"]
    
    file_info = None
    node_images_paths = None # –ë—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—É—Ç–∏ –∫ –ª–æ–∫–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–∞–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    page_id_to_name_map = {}

    # 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ
    try:
        await message.answer("--- *–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ* ---", parse_mode='MarkdownV2')
        file_info = await get_figma_file(file_id, base_dir)
        if file_info and file_info.get('document'):
            analysis_prompt_parts.append("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ:\n")
            analysis_prompt_parts.append(f"  –ò–º—è: {file_info.get('name')}\n")
            analysis_prompt_parts.append(f"  –ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {file_info.get('lastModified')}\n")
            
            pages = file_info['document'].get('children', [])
            analysis_prompt_parts.append(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü (canvas): {len(pages)}\n")
            await message.answer(f"‚úÖ *–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ –ø–æ–ª—É—á–µ–Ω–∞\\!* –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: `{len(pages)}`", parse_mode='MarkdownV2')

            node_ids_to_fetch_images = []
            if pages:
                for page in pages:
                    if page.get('id') and page.get('name'):
                        node_ids_to_fetch_images.append(page['id'])
                        page_id_to_name_map[page['id']] = page['name']
            
            # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å—Ç—Ä–∞–Ω–∏—Ü
            if node_ids_to_fetch_images:
                await message.answer(f"--- *–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è* `{len(node_ids_to_fetch_images)}` *—Å—Ç—Ä–∞–Ω–∏—Ü* ---", parse_mode='MarkdownV2')
                node_images_paths = await get_figma_node_images(file_id, node_ids_to_fetch_images, base_dir)
                
                if node_images_paths:
                    valid_image_paths_count = sum(1 for path in node_images_paths.values() if path)
                    analysis_prompt_parts.append(f"  –ü–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü: {valid_image_paths_count} (–∏–∑ {len(node_ids_to_fetch_images)} –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö)\n")
                    await message.answer(f"‚úÖ *–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –∑–∞–≥—Ä—É–∂–µ–Ω—ã\\!* –û—Ç–ø—Ä–∞–≤–ª—è—é –∏—Ö\\.\\.\\.", parse_mode='MarkdownV2')
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü
                    for node_id, local_image_path in node_images_paths.items():
                        if local_image_path:
                            page_name = page_id_to_name_map.get(node_id, node_id)
                            caption = f"üìÑ *–°—Ç—Ä–∞–Ω–∏—Ü–∞:* `{escape_markdown(page_name)}`"
                            await send_image_safely(message, local_image_path, caption)
                            await asyncio.sleep(0.5) # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
                        else:
                            page_name = page_id_to_name_map.get(node_id, node_id)
                            await message.answer(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã `{escape_markdown(page_name)}` –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–æ\\.", parse_mode='MarkdownV2')

                    analysis_prompt_parts.append("\n–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å—Ç—Ä–∞–Ω–∏—Ü:\n")

                    for node_id, local_image_path in node_images_paths.items():
                        if not local_image_path: # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –±—ã–ª–æ —Å–∫–∞—á–∞–Ω–æ
                            print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–∑–ª–∞ {node_id} –Ω–µ –±—ã–ª–æ —Å–∫–∞—á–∞–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑.")
                            analysis_prompt_parts.append(f"\n–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_id_to_name_map.get(node_id, node_id)}' (ID: {node_id}): –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–æ.\n")
                            continue

                        page_name = page_id_to_name_map.get(node_id, node_id)
                        page_analysis_file_name = f"page_analysis_{node_id.replace(':', '_')}.txt"
                        page_analysis_file_path = base_dir / page_analysis_file_name
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –≥–æ—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –¥–∏—Å–∫–µ
                        if page_analysis_file_path.exists():
                            print(f"–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}', –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞: {page_analysis_file_name}")
                            try:
                                with open(page_analysis_file_path, 'r', encoding='utf-8') as f:
                                    existing_analysis = f.read().strip()
                                if existing_analysis:
                                    analysis_prompt_parts.append(f"\n–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (ID: {node_id}):\n{existing_analysis}\n")
                                    await message.answer(f"üîç *–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã* `{escape_markdown(page_name)}` *–∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –∫–µ—à–∞\\!*", parse_mode='MarkdownV2')
                                    await send_formatted_message(message, existing_analysis, f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}'")
                                    await asyncio.sleep(0.5)
                                    continue
                                else:
                                    print(f"–§–∞–π–ª –∞–Ω–∞–ª–∏–∑–∞ –ø—É—Å—Ç–æ–π, –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑.")
                            except Exception as e:
                                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}. –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑.")
                        
                        await message.answer(f"--- *–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã* `{escape_markdown(page_name)}` *(ID: {escape_markdown(node_id)})* ---", parse_mode='MarkdownV2')
                        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª: {local_image_path}")

                        page_node = next((p for p in pages if p.get('id') == node_id), None)
                        actual_page_width = 0
                        
                        # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —à–∏—Ä–∏–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                        if page_node:
                            # –ú–µ—Ç–æ–¥ 1: absoluteBoundingBox
                            if page_node.get('absoluteBoundingBox') and page_node['absoluteBoundingBox'].get('width', 0) > 0:
                                actual_page_width = page_node['absoluteBoundingBox']['width']
                                print(f"–®–∏—Ä–∏–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ absoluteBoundingBox: {actual_page_width}px")
                            
                            # –ú–µ—Ç–æ–¥ 2: –µ—Å–ª–∏ absoluteBoundingBox –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑ children
                            elif not actual_page_width and page_node.get('children'):
                                max_right = 0
                                min_left = float('inf')
                                for child in page_node['children']:
                                    if child.get('absoluteBoundingBox'):
                                        child_bbox = child['absoluteBoundingBox']
                                        child_left = child_bbox.get('x', 0)
                                        child_width = child_bbox.get('width', 0)
                                        child_right = child_left + child_width
                                        max_right = max(max_right, child_right)
                                        min_left = min(min_left, child_left)
                                
                                if max_right > 0 and min_left != float('inf'):
                                    actual_page_width = max_right - min_left
                                    print(f"–®–∏—Ä–∏–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—ã—á–∏—Å–ª–µ–Ω–∞ –∏–∑ –¥–æ—á–µ—Ä–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {actual_page_width}px (–æ—Ç {min_left} –¥–æ {max_right})")
                            
                            # –ú–µ—Ç–æ–¥ 3: –ø–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä—ã canvas/viewport
                            if not actual_page_width and page_node.get('prototypeDevice'):
                                device = page_node['prototypeDevice']
                                if device.get('size') and device['size'].get('width'):
                                    actual_page_width = device['size']['width']
                                    print(f"–®–∏—Ä–∏–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ prototypeDevice: {actual_page_width}px")
                        
                        # –ï—Å–ª–∏ –≤—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        if actual_page_width <= 0:
                            actual_page_width = 1920  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –¥–ª—è desktop
                            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —à–∏—Ä–∏–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {actual_page_width}px")

                        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        current_page_analysis_prompt = IMAGE_ANALYSE_PROMPT_TEMPLATE
                        current_page_analysis_prompt = current_page_analysis_prompt.replace("{{PAGE_NAME}}", page_name)
                        current_page_analysis_prompt = current_page_analysis_prompt.replace("{{NODE_ID}}", node_id)
                        current_page_analysis_prompt = current_page_analysis_prompt.replace("{{ACTUAL_PAGE_WIDTH}}", str(actual_page_width))

                        page_image_analysis_response_parts = []

                        if actual_page_width > COLUMN_WIDTH_THRESHOLD:
                            await message.answer(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ `{escape_markdown(page_name)}` *(—à–∏—Ä–∏–Ω–∞: {actual_page_width}px)* –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ —à–∏—Ä–æ–∫–∞—è\\.", parse_mode='MarkdownV2')
                            
                            # –ó–∞–ø—Ä–æ—Å –∫ LLM ‚Ññ1: –µ—Å—Ç—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∏?
                            is_multi_column_prompt = (
                                f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (ID: {node_id}). "
                                f"–®–∏—Ä–∏–Ω–∞ —Ö–æ–ª—Å—Ç–∞: {actual_page_width}px. "
                                "–≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –û–ß–ï–ù–¨ –®–ò–†–û–ö–û–ï. –í–µ—Ä–æ—è—Ç–Ω–æ, –æ–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –ù–ï–°–ö–û–õ–¨–ö–û –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —ç–∫—Ä–∞–Ω–æ–≤/–º–∞–∫–µ—Ç–æ–≤, "
                                "—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã—Ö –í –ö–û–õ–û–ù–ö–ê–• (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ —Ä—è–¥–æ–º –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º). "
                                "–°–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–∞–∫–∏—Ö –∫–æ–ª–æ–Ω–æ–∫? –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ '–¥–∞' –∏–ª–∏ '–Ω–µ—Ç'."
                            )
                            is_multi_column_response = await analyze_figma_data_with_llm(is_multi_column_prompt, local_image_path, max_tokens=50)
                            print(f"LLM –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –Ω–∞–ª–∏—á–∏–∏ –∫–æ–ª–æ–Ω–æ–∫: '{is_multi_column_response}'")
                            await message.answer(f"LLM –æ—Ç–≤–µ—Ç –æ –Ω–∞–ª–∏—á–∏–∏ –∫–æ–ª–æ–Ω–æ–∫: `{escape_markdown(is_multi_column_response)}`", parse_mode='MarkdownV2')

                            if '–¥–∞' in is_multi_column_response.lower():
                                # –ó–∞–ø—Ä–æ—Å –∫ LLM ‚Ññ2: —Å–∫–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–æ–∫?
                                count_columns_prompt = (
                                    f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (ID: {node_id}) —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–æ–∫. "
                                    "–°–∫–æ–ª—å–∫–æ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (—ç–∫—Ä–∞–Ω–æ–≤/–º–∞–∫–µ—Ç–æ–≤) —Ç—ã –≤–∏–¥–∏—à—å –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏? "
                                    "–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–º."
                                )
                                count_columns_response = await analyze_figma_data_with_llm(count_columns_prompt, local_image_path, max_tokens=50)
                                print(f"LLM –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–æ–ª–æ–Ω–æ–∫: '{count_columns_response}'")
                                await message.answer(f"LLM –æ—Ç–≤–µ—Ç –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–æ–ª–æ–Ω–æ–∫: `{escape_markdown(count_columns_response)}`", parse_mode='MarkdownV2')
                                
                                try:
                                    num_expected_columns = int(count_columns_response.strip())
                                    if num_expected_columns <= 0:
                                        raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º.")
                                    print(f"LLM –æ–ø—Ä–µ–¥–µ–ª–∏–ª {num_expected_columns} –∫–æ–ª–æ–Ω–æ–∫.")
                                    await message.answer(f"LLM –æ–ø—Ä–µ–¥–µ–ª–∏–ª `{num_expected_columns}` –∫–æ–ª–æ–Ω–æ–∫\\.", parse_mode='MarkdownV2')

                                    # –í—ã–∑–æ–≤ split_image.py
                                    # split_image_intellectually –æ–∂–∏–¥–∞–µ—Ç –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
                                    # –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—Ä–µ–∑–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–∏ –≤ ./columns_py_opencv_actual_images/image_name_stem/column_X.png
                                    
                                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
                                    original_image_path_obj = Path(local_image_path)
                                    image_name_stem = original_image_path_obj.stem
                                    columns_output_base_dir = base_project_dir / 'columns_py_opencv_actual_images'
                                    columns_output_dir_for_image = columns_output_base_dir / image_name_stem
                                    ensure_dir_exists(columns_output_dir_for_image) # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

                                    # split_image_intellectually –∏—Å–ø–æ–ª—å–∑—É–µ—Ç cv2.imread, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–µ–¥–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
                                    split_columns_meta = split_image_intellectually(
                                        image_src=str(local_image_path), # –ü—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                                        expected_columns=num_expected_columns,
                                        # mock_image_width –∏ height –Ω–µ —Ç–∞–∫ –≤–∞–∂–Ω—ã, –µ—Å–ª–∏ actual_image_loaded –≤ split_image_intellectually
                                    )

                                    if split_columns_meta and len(split_columns_meta) > 0:
                                        await message.answer(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±—ã–ª–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ `{len(split_columns_meta)}` –∫–æ–ª–æ–Ω–æ–∫\\.", parse_mode='MarkdownV2')
                                        for i, col_meta in enumerate(split_columns_meta):
                                            # –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ
                                            # split_image.py —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –∫–∞–∫ column_1.png, column_2.png –∏ —Ç.–¥.
                                            # –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ./columns_py_opencv_actual_images/<image_name_without_ext>/
                                            
                                            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–ª–æ–Ω–∫–∏, –∫–∞–∫ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç split_image.py –≤ main()
                                            column_file_name = f"column_{i + 1}.png"
                                            if col_meta["saved_path"] and Path(col_meta["saved_path"]).exists():
                                                column_image_path = Path(col_meta["saved_path"])
                                                await message.answer(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–ª–æ–Ω–∫—É `{i+1}/{len(split_columns_meta)}` *(—Ñ–∞–π–ª: {escape_markdown(str(column_image_path))})*\\.\\.\\.", parse_mode='MarkdownV2')
                                                
                                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –ø–µ—Ä–µ–¥ –µ—ë –∞–Ω–∞–ª–∏–∑–æ–º
                                                caption_col = f"üì± *–ö–æ–ª–æ–Ω–∫–∞:* `{escape_markdown(column_image_path.stem.replace('_', ' ').title())}`"
                                                await send_image_safely(message, str(column_image_path), caption_col)
                                                await asyncio.sleep(0.5) # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

                                                # –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –û–î–ù–û–ô –ö–û–õ–û–ù–ö–ò
                                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ IMAGE_ANALYSE_PROMPT_TEMPLATE, –Ω–æ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º, —á—Ç–æ —ç—Ç–æ –∫–æ–ª–æ–Ω–∫–∞
                                                column_analysis_prompt = (
                                                    f"–≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∏–∑ {len(split_columns_meta)} –∫–æ–ª–æ–Ω–æ–∫ (–∫–æ–ª–æ–Ω–∫–∞ {i+1}) "
                                                    f"–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}'. \n\n"
                                                    f"{current_page_analysis_prompt}" # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                                                )
                                                
                                                col_analysis_response = await analyze_figma_data_with_llm(column_analysis_prompt, str(column_image_path), 4000)
                                                page_image_analysis_response_parts.append(f"\n–ê–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–∫–∏ {i+1}:\n{col_analysis_response}\n")
                                                await send_formatted_message(message, col_analysis_response, f"üîç –ê–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–∫–∏ {i+1} —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}'")
                                                await asyncio.sleep(0.5)
                                            else:
                                                print(f"–§–∞–π–ª –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ {i+1} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {col_meta.get('saved_path', 'N/A')}")
                                                page_image_analysis_response_parts.append(f"\n–ê–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–∫–∏ {i+1}: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.\n")
                                                await message.answer(f"‚ùå –§–∞–π–ª –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ `{i+1}` –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: `{escape_markdown(str(col_meta.get('saved_path', 'N/A')))}`", parse_mode='MarkdownV2')
                                    else:
                                        print("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–æ–Ω–∫–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ü–µ–ª–∏–∫–æ–º.")
                                        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–æ–Ω–∫–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ü–µ–ª–∏–∫–æ–º\\.", parse_mode='MarkdownV2')
                                        # –î–æ–±–∞–≤–ª—è–µ–º —É–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è LLM, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —à–∏—Ä–æ–∫–æ–µ, –Ω–æ –Ω–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–æ
                                        wide_image_notice = (
                                            f"–í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (ID: {node_id}) –û–ß–ï–ù–¨ –®–ò–†–û–ö–û–ï "
                                            f"(—à–∏—Ä–∏–Ω–∞ —Ö–æ–ª—Å—Ç–∞: {actual_page_width}px). –û–Ω–æ –Ω–µ –±—ã–ª–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ –∫–æ–ª–æ–Ω–∫–∏. "
                                            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—á—Ç–∏ —ç—Ç–æ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏ –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —ç–∫—Ä–∞–Ω—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å.\n\n"
                                        )
                                        llm_response = await analyze_figma_data_with_llm(wide_image_notice + current_page_analysis_prompt, local_image_path, 4000)
                                        page_image_analysis_response_parts.append(llm_response)
                                        await send_formatted_message(message, llm_response, f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (—Ü–µ–ª–∏–∫–æ–º)")
                                except ValueError as e:
                                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç LLM: {e}. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ü–µ–ª–∏–∫–æ–º.")
                                    await message.answer(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç LLM: `{escape_markdown(str(e))}`\\. –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ü–µ–ª–∏–∫–æ–º\\.", parse_mode='MarkdownV2')
                                    llm_response = await analyze_figma_data_with_llm(current_page_analysis_prompt, local_image_path, 4000)
                                    page_image_analysis_response_parts.append(llm_response)
                                    await send_formatted_message(message, llm_response, f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (—Ü–µ–ª–∏–∫–æ–º)")
                            else: # LLM –æ—Ç–≤–µ—Ç–∏–ª "–Ω–µ—Ç" –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –∫–æ–ª–æ–Ω–∫–∞—Ö
                                print("LLM –Ω–µ —Å—á–∏—Ç–∞–µ—Ç, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–æ–∫. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ü–µ–ª–∏–∫–æ–º.")
                                await message.answer("LLM –Ω–µ —Å—á–∏—Ç–∞–µ—Ç, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–æ–∫\\. –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ü–µ–ª–∏–∫–æ–º\\.", parse_mode='MarkdownV2')
                                llm_response = await analyze_figma_data_with_llm(current_page_analysis_prompt, local_image_path, 4000)
                                page_image_analysis_response_parts.append(llm_response)
                                await send_formatted_message(message, llm_response, f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (—Ü–µ–ª–∏–∫–æ–º)")
                        else: # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —à–∏—Ä–æ–∫–æ–µ
                            print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ '{page_name}' (—à–∏—Ä–∏–Ω–∞: {actual_page_width}px) –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ —à–∏—Ä–æ–∫–∞—è. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑.")
                            await message.answer(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ `{escape_markdown(page_name)}` *(—à–∏—Ä–∏–Ω–∞: {actual_page_width}px)* –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ —à–∏—Ä–æ–∫–∞—è\\. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑\\.", parse_mode='MarkdownV2')
                            llm_response = await analyze_figma_data_with_llm(current_page_analysis_prompt, local_image_path, 4000)
                            page_image_analysis_response_parts.append(llm_response)
                            await send_formatted_message(message, llm_response, f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}'")
                        
                        final_page_analysis = "".join(page_image_analysis_response_parts)
                        save_data_to_file(page_analysis_file_path, final_page_analysis, is_json=False)
                        print(f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {page_analysis_file_name}")
                        analysis_prompt_parts.append(f"\n–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_name}' (ID: {node_id}):\n{final_page_analysis}\n")

                else: # if node_images_paths
                    analysis_prompt_parts.append("  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã.\n")
                    await message.answer("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã\\.", parse_mode='MarkdownV2')
            else: # if node_ids_to_fetch_images
                analysis_prompt_parts.append("  –ù–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n")
                await message.answer("‚ùå –ù–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\\.", parse_mode='MarkdownV2')
        else: # if file_info
            analysis_prompt_parts.append("  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ.\n")
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ Figma.")
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ Figma\\.", parse_mode='MarkdownV2')
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö: {e}")
        analysis_prompt_parts.append(f"  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö: {e}\n")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö: `{escape_markdown(str(e))}`", parse_mode='MarkdownV2')

    # 3. –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
    try:
        await message.answer("\n--- *–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤* ---", parse_mode='MarkdownV2')
        comments_data = await get_figma_comments(file_id, base_dir)
        if comments_data and comments_data.get('comments'):
            comments_list = comments_data['comments']
            analysis_prompt_parts.append(f"\n–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ ({len(comments_list)} —à—Ç.):\n")
            if comments_list:
                for i, comment in enumerate(comments_list[:5]): # –ü–µ—Ä–≤—ã–µ 5 –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                    analysis_prompt_parts.append(f"  {i + 1}. {comment.get('message', '')[:100]}...\n")
                if len(comments_list) > 5:
                    analysis_prompt_parts.append(f"  ... –∏ –µ—â–µ {len(comments_list) - 5} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.\n")
                await message.answer(f"‚úÖ *–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ–ª—É—á–µ–Ω—ã\\!* –ù–∞–π–¥–µ–Ω–æ: `{len(comments_list)}`", parse_mode='MarkdownV2')
            else:
                analysis_prompt_parts.append("  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–µ—Ç.\n")
                await message.answer("‚ÑπÔ∏è –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–µ—Ç\\.", parse_mode='MarkdownV2')
        else:
            analysis_prompt_parts.append("  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏.\n")
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏\\.", parse_mode='MarkdownV2')
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {e}")
        analysis_prompt_parts.append(f"  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {e}\n")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: `{escape_markdown(str(e))}`", parse_mode='MarkdownV2')

    # 4. –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
    analysis_prompt_parts.append("\n\n--- –ò—Ç–æ–≥–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è LLM ---\n")
    
    if FINAL_ANALYSE_PROMPT_TEMPLATE:
        analysis_prompt_parts.append(FINAL_ANALYSE_PROMPT_TEMPLATE)
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞ .env.final_analyse_prompt ({len(FINAL_ANALYSE_PROMPT_TEMPLATE)} —Å–∏–º–≤–æ–ª–æ–≤)")
    else:
        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        fallback_prompt = """
–ù–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤—ã—à–µ, –ø—Ä–æ–≤–µ–¥–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Figma —Ñ–∞–π–ª–∞ –∏ –¥–∞–π –æ—Ü–µ–Ω–∫—É –µ–≥–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏.

–í–∫–ª—é—á–∏ –≤ –∞–Ω–∞–ª–∏–∑:
1. –û–±—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é —Ñ–∞–π–ª–∞
2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü
3. –ö–∞—á–µ—Å—Ç–≤–æ –¥–∏–∑–∞–π–Ω–∞ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
4. –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º–∞
5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

–û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: [–ü—Ä–æ—Å—Ç–æ–π/–°—Ä–µ–¥–Ω–∏–π/–°–ª–æ–∂–Ω—ã–π/–û—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π]
"""
        analysis_prompt_parts.append(fallback_prompt.strip())
        print("–í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç, —Ç–∞–∫ –∫–∞–∫ .env.final_analyse_prompt –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
        await message.answer("‚ö†Ô∏è *–í–ù–ò–ú–ê–ù–ò–ï*: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\\.", parse_mode='MarkdownV2')

    final_analysis_prompt_text = "".join(analysis_prompt_parts)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ LLM
    final_prompt_file_path = base_dir / 'final_analysis_prompt.txt'
    save_data_to_file(final_prompt_file_path, final_analysis_prompt_text, is_json=False)
    print(f"–ò—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {final_prompt_file_path}")
    
    await message.answer("\n--- *–ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é LLM* ---", parse_mode='MarkdownV2')
    await message.answer("–í—ã–ø–æ–ª–Ω—è—é –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö Figma\\.\\.\\. *(—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)*", parse_mode='MarkdownV2')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –≥–æ—Ç–æ–≤—ã–π –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
    summary_file_path = base_dir / 'analysis_summary.txt'
    if summary_file_path.exists():
        print(f"–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞: {summary_file_path}")
        await message.answer("üîç *–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑, –∑–∞–≥—Ä—É–∂–∞—é –∏–∑ —Ñ–∞–π–ª–∞\\!*", parse_mode='MarkdownV2')
        try:
            with open(summary_file_path, 'r', encoding='utf-8') as f:
                llm_analysis_result = f.read().strip()
            if not llm_analysis_result:
                print("–§–∞–π–ª –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—É—Å—Ç–æ–π, –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑.")
                await message.answer("–§–∞–π–ª –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—É—Å—Ç–æ–π, –≤—ã–ø–æ–ª–Ω—è—é –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑\\.", parse_mode='MarkdownV2')
                llm_analysis_result = await analyze_figma_data_with_llm(final_analysis_prompt_text, None, 6000)
                save_data_to_file(summary_file_path, llm_analysis_result, is_json=False)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}. –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑.")
            await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: `{escape_markdown(str(e))}`\\. –í—ã–ø–æ–ª–Ω—è—é –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑\\.", parse_mode='MarkdownV2')
            llm_analysis_result = await analyze_figma_data_with_llm(final_analysis_prompt_text, None, 6000)
            save_data_to_file(summary_file_path, llm_analysis_result, is_json=False)
    else:
        # –î–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è, —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
        llm_analysis_result = await analyze_figma_data_with_llm(final_analysis_prompt_text, None, 6000)
        save_data_to_file(summary_file_path, llm_analysis_result, is_json=False)

    print("\n--- –ó–∞–≤–µ—Ä—à–µ–Ω–æ ---")
    print(f"–í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {base_dir}")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ LLM —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {summary_file_path}")
    await message.answer("‚úÖ *–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω\\!* –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã\\.", parse_mode='MarkdownV2')
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ allcdsps_figmar.py
    # print("\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ ---")
    # print(llm_analysis_result)

    return {
        "summary": llm_analysis_result,
        "dataPath": str(base_dir),
        "summaryFilePath": str(summary_file_path)
    }

def get_figma_url_from_user() -> str:
    
    
    while True:
        figma_url = "https://www.figma.com/design/sfBOYWVpWlJvYZyI7g6MxD/–ê—ç—Ä–æ–∫–ª—É–±--Copy-?node-id=48-1883&t=dV5UJDg3FRuECK92-1"
        
        if not figma_url:
            print("–û—à–∏–±–∫–∞: –ü—É—Å—Ç–∞—è —Å—Å—ã–ª–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            continue
        
        # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è URL
        if not figma_url.startswith('https://www.figma.com/'):
            print("–û—à–∏–±–∫–∞: –°—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω–∞ –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'https://www.figma.com/'. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ URL —Å–æ–¥–µ—Ä–∂–∏—Ç file –∏–ª–∏ design
        if '/file/' not in figma_url and '/design/' not in figma_url:
            print("–û—à–∏–±–∫–∞: –°—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å '/file/' –∏–ª–∏ '/design/'. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            continue
        
        return figma_url

# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) ---
# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —É–¥–∞–ª–µ–Ω–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ —Ç–µ–ø–µ—Ä—å –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
