# Сервис для проверки договоров

## Описание Проекта

Данный сервис предназначен для автоматизированного анализа юридических договоров. Пользователь загружает текст договора (в форматах PDF или DOC), после чего система асинхронно анализирует каждый смысловой пункт/абзац. Прогресс анализа отображается в реальном времени. По завершении анализа, при наведении на элемент текста справа отображаются потенциальные риски, рекомендации по улучшению формулировок и информация о том, как данная часть текста соотносится с другими разделами договора.

Сервис использует универсальный LLM-коннектор, который может работать как с DeepSeek API, так и с OpenAI API (в зависимости от настроек в `.env`), для анализа текста и кэширует результаты анализа для повышения производительности и возможности отслеживания прогресса.

Проект также включает в себя набор SEO-оптимизированных HTML-страниц, каждая из которых посвящена определенному ключевому запросу, связанному с юридическим анализом документов. Контент этих страниц будет обогащаться данными из Яндекс.Вордстата.

## Технологический Стек

*   **Бэкенд**: Python (Flask)
    *   Парсинг документов: `pdfminer.six`, `python-docx`
    *   Взаимодействие с API: `requests`
    *   Кэширование: Файловая система (JSON)
    *   Шаблонизатор: Jinja2
*   **Фронтенд**: Vanilla JavaScript
*   **API для анализа**: Универсальный LLM-коннектор (DeepSeek/OpenAI)
*   **API для SEO-оптимизации**: Яндекс.Вордстат API
*   **Хранение контента**: Markdown с YAML Front Matter

## Структура Проекта

```
hababru/
├── public/                   # Статические ресурсы и скомпилированный фронтенд
│   ├── css/                  # Стили CSS
│   │   └── style.css
│   ├── js/                   # Клиентские скрипты JavaScript
│   │   └── app.js
│   ├── assets/               # Изображения, шрифты и т.д.
│   └── favicon.ico
├── src/                      # Исходный код
│   ├── backend/              # Логика бэкенда (Python)
│   │   ├── api/              # API эндпоинты
│   │   │   └── v1/
│   │   │       ├── __init__.py
│   │   │       └── contract_analyzer.py # Эндпоинт для анализа договоров
│   │   ├── services/         # Бизнес-логика
│   │   │   ├── __init__.py
│   │   │   ├── llm_service.py      # Универсальный LLM-коннектор (DeepSeek/OpenAI)
│   │   │   ├── parsing_service.py  # Парсинг PDF/DOC
│   │   │   ├── cache_service.py    # Логика кэширования
│   │   │   ├── seo_service.py      # Сервис для работы с SEO-страницами (парсинг, рендеринг)
│   │   │   └── yandex_wordstat_service.py # Взаимодействие с Яндекс.Вордстат API
│   │   ├── templates/        # HTML-шаблоны Jinja2
│   │   │   └── index_template.html # Единый шаблон для всех страниц
│   │   ├── utils/            # Вспомогательные функции
│   │   │   └── __init__.py
│   │   └── main.py           # Точка входа бэкенд-приложения
│   ├── frontend/             # Исходный код фронтенда (для основного интерфейса)
│   │   ├── components/       # UI компоненты
│   │   │   ├── __init__.py
│   │   │   ├── ContractUploader.js
│   │   │   ├── ContractView.js
│   │   │   └── AnalysisPanel.js
│   │   ├── services/         # Сервисы фронтенда (вызовы API)
│   │   │   └── __init__.py
│   │   └── App.js            # Главный компонент фронтенд-приложения
│   ├── shared/               # Общий код для фронтенда и бэкенда (например, типы)
│   │   └── __init__.py
├── content/                  # Исходные файлы контента
│   ├── seo_pages/            # Директория для SEO-страниц в формате .md
│   │   ├── __init__.py
│   │   ├── proverka-dogovorov.md
│   │   ├── analiz-dogovora-online.md
│   │   ├── proverka-dogovora-arendy/ # Примеры для SEO-страницы "проверка договора аренды"
│   │   │   └── dogovor_arendy_kommercheskoy_nedvizhimosti_primer.pdf
│   │   ├── analiz-dogovora-postavki/ # Примеры для SEO-страницы "анализ договора поставки"
│   │   │   └── dogovor_postavki_tovarov_obrazec.docx
│   │   ├── yuridicheskaya-ekspertiza-dogovora-uslug/ # Примеры для SEO-страницы "юридическая экспертиза договора услуг"
│   │   │   └── dogovor_okazaniya_yuridicheskih_uslug_shablon.pdf
│   │   └── ...               # Другие SEO-страницы (по одной на каждый ключ)
│   └── __init__.py
├── data/                     # Хранилище данных
│   ├── cache/                # Кэш договоров и анализов (например, JSON файлы)
│   │   └── __init__.py
│   ├── uploads/              # Временно загруженные файлы
│   │   └── __init__.py
│   ├── sample_contracts/     # Примеры договоров (только default_nda.txt остался здесь)
│   │   └── default_nda.txt   # Пример договора по умолчанию (используется при обычном запуске)
│   └── __init__.py
├── .env                      # Переменные окружения (API ключи, токены)
├── README.md                 # Описание проекта, структура, план работы, инструкции
└── requirements.txt          # Зависимости Python
```

## План Работы (Выполнено)

1.  **Инициализация Проекта:**
    *   Создана корневая директория `hababru/`.
    *   Создана базовая структура папок внутри `hababru/`.
    *   Создан файл `hababru/.env` с `DEEPSEEK_API_KEY`, `YANDEX_CLIENT_ID`, `YANDEX_CLIENT_SECRET`, `YANDEX_REDIRECT_URI`.
    *   Создан файл `hababru/README.md` с этим подробным описанием.
    *   Подготовлен файл `data/sample_contracts/default_nda.txt` с примером договора.
    *   Созданы все необходимые `__init__.py` файлы для корректной работы пакетов Python.
    *   Установлены зависимости из `requirements.txt`.

2.  **Разработка Бэкенда (Python с Flask):**
    *   Настроен Flask-фреймворк и реализован `src/backend/main.py` как точка входа.
    *   Реализован `src/backend/services/parsing_service.py` для парсинга PDF/DOCX и сегментации текста на пункты/абзацы.
    *   Реализован `src/backend/services/llm_service.py` как универсальный LLM-коннектор, поддерживающий DeepSeek и OpenAI API.
    *   **Обновлено**: Реализован `src/backend/services/cache_service.py` для кэширования результатов анализа и управления статусом асинхронных задач.
    *   **Обновлено**: Реализован `src/backend/api/v1/contract_analyzer.py` с API-эндпоинтами `/upload_contract`, `/start_analysis` (для запуска асинхронного анализа), `/get_analysis_status/<task_id>` (для получения прогресса) и `/get_sample_contract`.
    *   Blueprint `contract_analyzer_bp` зарегистрирован в `main.py`.
    *   **Обновлено**: Главная страница и SEO-страницы теперь рендерятся с использованием единого шаблона `src/backend/templates/index_template.html`.

3.  **Разработка Фронтенда (Vanilla JS):**
    *   Статический файл `public/index.html` удален. Главная страница теперь рендерится бэкендом.
    *   Создан `public/css/style.css` для общих стилей.
    *   **Обновлено**: Создан `public/js/app.js` с единой логикой для главной и SEO-страниц:
        *   Добавлен `public/favicon.ico`.
        *   Рандомизация реквизитов примера договора.
        *   Загрузка примера договора через API `/api/v1/get_sample_contract`.
        *   Отображение текста договора по пунктам/абзацам.
        *   Базовая логика для отображения панели анализа при наведении.
        *   Обработчик для загрузки пользовательских файлов и отправки их на анализ.
        *   **Новое**: Реализован асинхронный запуск анализа через `/api/v1/start_analysis`.
        *   **Новое**: Добавлена логика периодического опроса `/api/v1/get_analysis_status/<task_id>` для отображения прогресса анализа (количество обработанных пунктов/абзацев и процент выполнения).
        *   **Новое**: Добавлены элементы UI (текстовое поле и прогресс-бар) для визуализации прогресса.
    *   **Новое**: На главную страницу (теперь через `index_template.html`) добавлен текст о сервисе и ссылки на существующие SEO-страницы договоров.

5.  **Унификация шаблонов и стилей:**
    *   Удален шаблон `src/backend/templates/seo_page_template.html`.
    *   Все страницы теперь используют единый шаблон `src/backend/templates/index_template.html`.
    *   Стили унифицированы в `public/css/style.css`.
    *   JavaScript-логика унифицирована в `public/js/app.js`.

6.  **Тестирование и Отладка:**
    *   Проверена базовая структура проекта и установка зависимостей.
    *   Проверена работа Flask-приложения и обслуживание статических файлов.
    *   Проверена загрузка примера договора через API.
    *   **Обновлено**: Проверена асинхронная работа анализа и отображение прогресса на фронтенде.

## Текущий Статус и Известные Проблемы

Все файлы проекта, включая бэкенд-сервисы, API-эндпоинты и базовый фронтенд, созданы согласно плану. Асинхронный анализ и отображение прогресса реализованы.

## Тестовый режим

Для отладки и проверки распознавания файла, вы можете использовать тестовый режим.
Перейдите по URL вида: `http://127.0.0.1:5001/?test=dubna.docx`
Где `dubna.docx` - это имя файла, который вы разместили в корневой директории проекта `hababru/`, в `hababru/src/` 


## Примеры договоров для SEO-страниц

Примеры договоров, специфичные для каждой SEO-оптимизированной страницы, теперь размещаются в соответствующих поддиректориях внутри `hababru/content/seo_pages/`.
Название поддиректории должно соответствовать ключевому слову или URL SEO-страницы. Например:
*   Для SEO-страницы `analiz-dogovora-arendy` примеры договоров размещаются в `hababru/content/seo_pages/analiz-dogovora-arendy/`. (при тестах сео страниц используй эту страницу по умолчанию)
*   Для SEO-страницы `analiz-dogovora-postavki` примеры договоров размещаются в `hababru/content/seo_pages/analiz-dogovora-postavki/`.

Это позволит в будущем реализовать логику загрузки релевантных примеров для каждой конкретной SEO-страницы.

## Инструкции по Запуску (Обновлено)

1.  **Клонирование репозитория:**
    ```bash
    git clone <URL_репозитория>
    cd hababru
    ```
2.  **Настройка переменных окружения:**
    *   Создайте файл `.env` в корневой директории проекта `hababru/`.
    *   Добавьте следующие переменные:
        ```
        DEEPSEEK_API_KEY=ВАШ_DEEPSEEK_API_KEY
        YANDEX_CLIENT_ID=ВАШ_YANDEX_CLIENT_ID
        YANDEX_CLIENT_SECRET=ВАШ_YANDEX_CLIENT_SECRET
        YANDEX_REDIRECT_URI=ВАШ_YANDEX_REDIRECT_URI
        YANDEX_OAUTH_TOKEN=ВАШ_YANDEX_OAUTH_TOKEN # Получите его после авторизации и подачи заявки
        ```
    *   **Важно**: Для `YANDEX_OAUTH_TOKEN` вам необходимо вручную получить токен и подать заявку на доступ к API Яндекс.Вордстата, как описано в документации.
    *   **Примечание**: Агент не будет изменять содержимое файла `.env`.


3.  **Запуск бэкенда:**
    *   
    *   **Запуск через PM2 (рекомендуется для production):**
        Запустите приложение с помощью PM2:
            ```bash

            # Или используя python3 напрямую
            pm2 stop "habab_allalldsps"
            pm2 delete habab_allalldsps
            pm2 flush habab_allalldsps
            pm2 start "python3 -m hababru.src.backend.main" --name "habab_allalldsps" 
            
            # для просмотра логов (таймаут нужен т.к. cline не продолжает работу пока не выйти в баш обратно из команды)
            timeout 10 pm2 logs habab_allalldsps
            ```
       

4.  **Доступ к сервису:**
    *   Основной интерфейс будет доступен по адресу `http://127.0.0.1:5001/` (или другой порт, указанный в конфигурации Flask).
    *   SEO-страницы будут доступны по соответствующим URL (например, `http://127.0.0.1:5001/analiz-dogovora-arendy`).

## Пример Договора по Умолчанию

Текст предоставленного вами "Соглашения о защите и неразглашении информации" сохранен в `data/sample_contracts/default_nda.txt`. При отображении на фронтенде его реквизиты (ФИО, ИНН, адреса, названия компаний и т.д.) будут заменены на случайные данные для демонстрации.

---
**Примечание:** Для полноценной работы с API Яндекс.Вордстата требуется ручное получение OAuth-токена и подача заявка на доступ к API через поддержку Яндекс.Директа.

## Обработка ошибок LLM API

В процессе работы сервиса могут возникать ошибки при взаимодействии с выбранным LLM API (DeepSeek или OpenAI), например, `Read timed out`. Для повышения стабильности работы рекомендуется рассмотреть следующие улучшения в `src/backend/services/llm_service.py`:
*   **Механизм повторных попыток (Retry Logic)**: Реализовать автоматические повторные попытки запросов к LLM API с экспоненциальной задержкой (exponential backoff) в случае временных ошибок (например, таймаутов или ошибок 5xx). Это поможет справиться с нестабильностью сети или временной недоступностью API.
*   **Более информативные сообщения об ошибках**: Улучшить логирование ошибок, чтобы они содержали больше контекста, например, полный текст ошибки от API, статус-коды HTTP и время, прошедшее до таймаута. Это упростит отладку и мониторинг.
*   **Конфигурируемые таймауты**: Сделать таймауты для запросов к LLM API конфигурируемыми, чтобы их можно было легко настраивать в зависимости от условий сети и ожидаемого времени ответа API.

## Генерация SEO-страниц

Для создания новой SEO-страницы или обновления существующей используйте скрипт `generate_seo_page.py`. Этот скрипт автоматически создает необходимую структуру директорий и генерирует контент (`source.md` и `generated_contract.txt`) на основе заданного ключевого слова.

**Использование:**

```bash
python src/backend/cli/generate_seo_page.py --keyword "ВАШЕ КЛЮЧЕВОЕ СЛОВО"
```

**Пример:**

Для создания страницы "анализ договора аренды недолго помещения" выполните:

```bash
python src/backend/cli/generate_seo_page.py --keyword "анализ договора аренды нежилого помещения"
```

Скрипт создаст директорию `content/seo_pages/analiz-dogovora-arendy-nedolgo-pomeshcheniya/` и заполнит ее необходимыми файлами.


## План по Автоматической Генерации SEO-страниц (Обновленный)

Эта секция описывает план по созданию системы для полуавтоматической генерации SEO-оптимизированных страниц на основе ключевых слов.

### Ключевые изменения в подходе:

1.  **Анализ Договора**:
    *   Скрипт генерации SEO-страницы (`src/backend/cli/generate_seo_page.py` через `src/backend/services/content_generation_service.py`) **не будет** сам запускать или сохранять результаты анализа сгенерированного договора.
    *   Он только сгенерирует текст договора и сохранит его в `content/seo_pages/[slug]/generated_contract.txt`.
    *   Когда пользователь впервые заходит на SEO-страницу (например, `/анализ-договора-аренды`), существующая система (которая обрабатывает `?test=файл.pdf`) автоматически подхватит `generated_contract.txt` для этой страницы и выполнит анализ "на лету". Результаты анализа будут отображаться, но не будут предварительно сохраняться в `source.md` генератором.

2.  **Яндекс.Вордстат и Фаллбэк**:
    *   В `.env` файле будет флаг `USE_YANDEX_WORDSTAT` (по умолчанию `false`, если отсутствует).
    *   **Если `USE_YANDEX_WORDSTAT=true`**:
        *   `ContentGenerationService` попытается получить `meta_keywords` и `related_keywords` из Яндекс.Вордстат.
        *   Если Вордстат недоступен, возвращает ошибку, или если флаг `USE_YANDEX_WORDSTAT` установлен в `false` изначально, то:
            *   `meta_keywords` и `related_keywords` будут сгенерированы с помощью DeepSeek на основе основного ключевого слова.
    *   **Если `USE_YANDEX_WORDSTAT=false`**:
        *   `meta_keywords` и `related_keywords` сразу генерируются DeepSeek.

### Обновленная структура `content/seo_pages/[slug]/source.md`:

```yaml
---
title: "Анализ договора аренды" # Генерируется из основного ключевого слова
meta_keywords: ["ключ1", "ключ2"] # Из Яндекс.Вордстат или сгенерированы DeepSeek
meta_description: "Сгенерированное описание..." # Сгенерировано DeepSeek
related_keywords: ["связанный ключ1", "связанный ключ2"] # Из Яндекс.Вордстат или сгенерированы DeepSeek
contract_file: "generated_contract.txt" # Путь к файлу сгенерированного текста договора
main_keyword: "анализ договора аренды" # Исходное ключевое слово для страницы
---
# Сгенерированный основной текст страницы (под формой)
# Этот текст также генерируется DeepSeek.
```

### Обновленный процесс в `src/backend/services/content_generation_service.py`:

1.  **Генерация текста договора**: На основе `main_keyword` с помощью LLM. Сохраняется в `content/seo_pages/[slug]/generated_contract.txt`.
2.  **Получение/Генерация ключевых слов (`meta_keywords`, `related_keywords`)**:
    *   Проверяется флаг `USE_YANDEX_WORDSTAT` в `.env` (по умолчанию `false`).
    *   Если `true` и Вордстат доступен: используются данные из `yandex_wordstat_service.py`.
    *   В противном случае (флаг `false` или Вордстат недоступен/ошибка): ключевые слова генерируются LLM.
3.  **Генерация `meta_description`**: С помощью LLM (на основе `main_keyword` и, возможно, полученных/сгенерированных `meta_keywords`).
4.  **Генерация основного текста страницы**: С помощью LLM (на основе `main_keyword`).
5.  **Сборка `source.md`**: Формируется файл `source.md` с полями: `title` (из `main_keyword`), `meta_keywords`, `meta_description`, `related_keywords`, `contract_file` (путь), `main_keyword` и сгенерированный основной текст страницы.

### Взаимодействие при отображении SEO-страницы (серверная часть):

1.  Пользователь запрашивает `/slug_страницы`.
2.  `seo_service.py` (или аналогичный обработчик):
    *   Загружает `content/seo_pages/[slug_страницы]/source.md` для получения метаданных и основного текста.
    *   Загружает содержимое файла `content/seo_pages/[slug_страницы]/generated_contract.txt`.
    *   **Передает текст договора существующей системе анализа** (которая работает для `?test=...`).
    *   Система анализа обрабатывает текст договора "на лету".
    *   Все данные (метаданные из `source.md`, основной текст из `source.md`, текст договора, результаты анализа "на лету") передаются в HTML-шаблон для рендеринга.

### Визуализация обновленного процесса генерации:
```mermaid
graph TD
    A[Запуск CLI: generate_seo_page --keyword "Ключевое слово"] --> B(Создание директории content/seo_pages/[slug]);
    B --> C(ContentGenerationService);

    subgraph ContentGenerationService
        C --> D{1. Генерация текста договора (LLM)};
        D --> E[generated_contract.txt];
        C --> F_ENV{2. Проверка флага USE_YANDEX_WORDSTAT};
        F_ENV -- "true" --> G_TRY_WORDSTAT{Попытка Яндекс.Вордстат};
        G_TRY_WORDSTAT -- "Успех" --> H_WORDSTAT_KEYS[meta_keywords, related_keywords (из Wordstat)];
        G_TRY_WORDSTAT -- "Неудача/Отключено" --> I_LLM_KEYS{Генерация ключей (LLM)};
        F_ENV -- "false" --> I_LLM_KEYS;
        I_LLM_KEYS --> J_LLM_KEYS_RES[meta_keywords, related_keywords (из LLM)];
        H_WORDSTAT_KEYS --> K_MERGED_KEYS((Собранные ключи));
        J_LLM_KEYS_RES --> K_MERGED_KEYS;
        K_MERGED_KEYS --> L{3. Генерация Meta Description (LLM)};
        L --> M[meta_description_text];
        K_MERGED_KEYS --> N{4. Генерация основного текста страницы (LLM)};
        N --> O[page_text_content];
        P[Все данные + main_keyword] --> Q_BUILD{5. Сборка source.md};
        Q_BUILD --> R_MD[source.md в content/seo_pages/[slug]/];
    end

    S[HTTP Запрос: GET /[slug]] --> T_FLASK(Flask Route);
    T_FLASK --> U_SEO_SVC(SeoService);
    U_SEO_SVC --> V_READ_FILES{Чтение source.md и generated_contract.txt};
    V_READ_FILES --> W_CONTRACT_DATA[Текст договора из generated_contract.txt];
    V_READ_FILES --> Z_METADATA[Метаданные и текст из source.md];
    W_CONTRACT_DATA --> X_ANALYSIS_SYSTEM{Передача текста в СУЩЕСТВУЮЩУЮ систему анализа};
    X_ANALYSIS_SYSTEM --> Y_LIVE_ANALYSIS[Результат анализа (на лету)];
    Y_LIVE_ANALYSIS & Z_METADATA --> AA_TEMPLATE{Передача всех данных в HTML-шаблон};
    AA_TEMPLATE --> AB_HTML[HTML Ответ];
```
